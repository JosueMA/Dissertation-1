The final chapter takes advantage of the Bayesian framework to implement effective (I expect) methods for the selection of item covariates. 
With MCMC methods, the doubly explanatory model may be estimated maintaining both the person and item residuals, and recently developed Bayesian cross-validation approximations are readily calculated from the conditional likelihood given these residuals after MCMC simulation. 
However, these approximations correspond to a cross-validation scheme in which holdout data include new responses from the same persons and same items. 
For inferences requiring, for example, cross-validation over items, I will show that a marginal variation of these approximations is superior (I expect).
The methods are first introduced for a simpler model and are then extend to the doubly explanatory model.


\section{WAIC and Bayesian LOO}

As a simple example, consider a hierarchical model (not cross-clustered) in which a response $y_{jk}$ has a likelihood, 
$p(y_{jk} | \theta_k)$, 
that is conditional on a cluster-specific parameter $\theta_k$. This parameter has a hierarchical prior,
$\theta_k \sim \mathrm{N}(0, \psi)$, and in turn the variance has as a prior
$\psi \sim \mathrm{log~N}(0, 1)$, an arbitrary choice. For Bayesian cross-validation, the pointwise predictive density is defined as the conditional likelihood integrated over the posterior distributions of all parameters. For the simple example, this quantity is
\begin{equation} 
	\mathrm{PD}_{jk} = 
	\iint
		p(y_{jk} | \theta_k)
		p(\theta_k | D, \psi)
		p(\psi | D)
	~d \theta_k d \psi
,\end{equation}
where $D$ represents all the data, in this case merely the complete response vector.
The log of $\mathrm{PD}_{jk}$ may be summed across observations to calculate a full data log-likelihood.
In an MCMC simulation with $S$ posterior draws, this quantity may be evaluated at each posterior draw $s$ as
\begin{equation} 
	\mathrm{PD}_{jk}^{(s)} = 
	p(y_{jk} | \theta_k^{(s)})
	p(\theta_k^{(s)} | D, \psi^{(s)})
	p(\psi^{(s)} | D)
,\end{equation}
where $\theta_k^{(s)}$ represents the posterior draw of $\theta_k$ at MCMC iteration $s$ and likewise for $\psi^{(s)}$.
$\mathrm{PD}_{jk}^{(s)}$ may be aggregated across draws to estimate the posterior distribution of $\mathrm{PD}_{jk}$. Usually this topic is discussed in terms of the \emph{log} pointwise predictive density (for example, \cite{gelman2014understanding}), but breaking from this norm simplifies some notation that follows.

Keeping with the simple example, WAIC \parencite{watanabe2010asymptotic}, a Bayesian information criteria, is defined as
\begin{equation} \label{eq:waic}
	\mathrm{WAIC} = 
		\sum_{k=1}^K \sum_{j=1}^J \log  
			\left (\frac{1}{S} \sum_{s=1}^{S} \mathrm{PD}_{jk}^{(s)} \right ) -
		\sum_{k=1}^K \sum_{j=1}^J V_{s=1}^{S} 
			\left ( \log \mathrm{PD}_{jk}^{(s)} \right )
\end{equation}
where $V_{s=1}^{S}$ represents the sample variance.
Like other information criteria, it has the form of log likelihood minus a penalty term. The penalty term for WAIC is estimated from the variances of the log pointwise predictive densities. Although the equation shows separate summations over $j$ and $k$, the summations are only a means of aggregating over the full data and do not really reflect the nested nature of the data. WAIC bears some similarity to DIC \parencite{Spiegelhalter2002} but is more stable \parencite{vehtari2015efficient}.

Bayesian LOO is an estimate of the $\mathrm{PD}_{jk}$ that would result from leave one out cross-validation. 
\textcite{gelfand1992model} propose estimating this quantity using importance sampling, and \textcite{vehtari2015efficient} propose smoothing the distribution of importance weights by fitting a generalized Pareto distribution to the upper tail of the weights.


\section{Marginal forms of WAIC and Bayesian LOO}

A limitation of cross-validation approximations relying on $\mathrm{PD}_{jk}^{(s)}$ is that they imply a cross-validation scheme in which the same clusters are represented in the holdout dataset. For inferences regarding cross-validation with new clusters, I propose a marginal predictive pointwise density:
\begin{equation} \label{eq:mpd-easy}
	\mathrm{MPD}_{k}^{(s)} = 
	%\log 
	\left (
		\left [ \int
			p(\check \theta | \psi^{(s)})
			\prod_{j} p(y_{jk} | \check \theta)
			~d \check \theta
    \right ]
		p(\psi^{(s)} | D)
	\right )
.\end{equation}
The accent is placed on $\check \theta$ to indicate that it is not 
drawn from its posterior distribution but from its ``prior'' distribution, given the posterior draw of $\psi^{(s)}$. 
In short, the bracketed quantity is the joint likelihood of cluster $k$ integrated over $p(\check \theta | \psi^{(s)})$, which is not directly influenced by data from cluster $k$.
This is similar to marginalizing over ``random effects'' in frequentist mixed models, except here it occurs at every posterior draw $s$. $\mathrm{MPD}_{k}^{(s)}$ may be used in place of $\mathrm{PD}_{jk}$ for calculating WAIC and Bayesian LOO when cross-validation with clusters is needed. The integration in Equation~\ref{eq:mpd-easy} has a closed form for linear models, and for models with non-linear link functions I proposed estimating it with adaptive quadrature \parencite{naylor1982applications}, which has been shown to work well for models with discrete outcomes and large clusters \parencite{rabe2005maximum}.

Returning now to the context of the doubly explanatory model, the pointwise predictive density is
\begin{equation} \label{eq:eirm-lpd}
	\mathrm{PD}_{ip}^{(s)} = 
		p(y_{ip} | \zeta_p^{(s)}, \epsilon_i^{(s)})
		p(\zeta_p^{(s)} | D, \sigma^{(s)})
		p(\epsilon_i^{(s)} | D, \tau^{(s)}) 
		p(\sigma^{(s)}, \tau^{(s)} | D)
,\end{equation}
where $D$ again represents all the data, in this case including all responses in $y$, the person covariate matrix $W$, and the item covariate matrix $X$. For models for cross-clustered data, including the doubly explanatory model, I propose calculating the marginal pointwise predictive density in such a way as to be marginal in regard to one set of clusters but not the other. For cross-validation over persons,
\begin{equation}
	\mathrm{MPD}_p^{(s)} = 
		\left [ \int
			p(\check \zeta | \sigma^{(s)})
			\prod_{i=1}^I	p(y_{ip} | \check \zeta, \epsilon_i^{(s)})
			~d \check \zeta 
		\right ]
		p(\epsilon^{(s)} | D, \tau^{(s)}) 
		p(\sigma^{(s)}, \tau^{(s)} | D)
\end{equation}
is appropriate. Here it is assumed that the same items would be administered to new person, and so the quantity is marginal only in regards to persons. On the other hand,
\begin{equation}
	\mathrm{MPD}_i^{(s)} = 
		\left [ \int
			p(\check \epsilon | \tau^{(s)})
			\prod_{p=1}^P	p(y_{ip} | \zeta^{(s)}, \check \epsilon_i)
			~d \check \epsilon 
		\right ]
		p(\zeta^{(s)} | D, \sigma^{(s)}) 
		p(\sigma^{(s)}, \tau^{(s)} | D)
,\end{equation}
which is marginal in regards to items, may be used for cross-validation over items.


\section{Simulation study 1: Linear responses}

I will conduct a simulation study, similar to those in Chapter~2, that evaluates the success that standard and marginal versions of WAIC and Bayesian LOO exhibit in selecting the correct model among models with differing item covariates. I will first use a version of the doubly descriptive model that is modified to have a continuous response variable. Doing so will allow me simultaneously study (1) how WAIC and Bayesian LOO perform when the likelihoods need not be approximated and (2) the accuracy of adaptive quadrature as compared against the exact likelihoods.

Owing to the relative slowness of MCMC simulation, this simulation study will involve fewer conditions as compared to those in Chapter~2 and may not incorporate holdout cross-validation. Also, if simulation study~2 (below) is highly successful, simulation study~1 may be abbreviated or omitted. Preliminary results indicate that adaptive quadrature works very well in simpler random intercept models. Also for the random intercept model, I find that the marginal forms of WAIC and Bayesian LOO are successful in choosing the generating model in a high proportion of replications.


\section{Simulation study 2: Categorical responses}

The second simulation study will use the unmodified doubly explanatory model. It will track the success that standard and marginal versions of WAIC and Bayesian LOO exhibit in selecting the correct model among models with differing item covariates. It will be very similar to simulation study~1, with the only difference being the binary response variable and the use of adaptive quadrature.